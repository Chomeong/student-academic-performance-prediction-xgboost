# ğŸ“ Studentsâ€™ Performance Classification

## ğŸ“Œ Overview
This project was my thesis, designed toÂ classify performanceÂ as low, medium, or highÂ based on factors other than grades. This project utilised Educational Data Mining (EDM) and the XGBoost algorithm to create a model that can predict student achievement. The goal was to build a model that classifies student achievement based on factors other than just their grades.

## ğŸ›  Technologies Used
- **Python** â€” Main programming language
- **Visual Studio Code** â€” Development environment
- **XGBoost** - Machine learning algorithm
- **Feature Selection** - Method

## ğŸ”— Document Related 
- **<a href="https://www.canva.com/design/DAGoJiIMxZk/v73rdOoz5e3-QhO7usMGXg/edit" target="_blank">Presentation File</a>**
- **<a href="https://drive.google.com/file/d/17TKtwrrQ3OZSe4VAP3PB5vh-qtI0T4Sw/view?usp=drive_link" target="_blank">Original Document</a>**

## ğŸ“„ Conclusion
- There are **ten factors** that are significant to student achievement, which are Relation, Parent Answering Survey, Parent School Satisfaction, Students' Absence Days, Gender, Nationality, Place of Birth, Raised Hands, Announcement View, and Visited Resource.
- The model was built using the **XGBoost algorithm** and **three experiments** were conducted with the **number of features, namely 16, 10, and 6**, where each feature will be tested again for the **data ratio, namely 70:15:15, 80:10:10, and 90:5:5**.
- The **best model performance** has **six features, a data ratio of 90:5:5, and undersampling** for imbalanced data with an **accuracy of 0.9583333333333334**.
- Model **accuracy increased** after **hyperparameter tuning**.
- The **data ratio affects the accuracy** of the model.
- In feature selection, **the most important thing** is not the number but **what features are selected**.

## ğŸ™‹â€â™€ï¸ Author
Developed by Clara Carissa

